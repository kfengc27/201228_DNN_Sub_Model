{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import regularizers\n",
    "import tensorboard\n",
    "tensorboard.__version__\n",
    "from sklearn.metrics import r2_score\n",
    "import pydot\n",
    "from tensorflow.keras.layers import Activation\n",
    "import threading\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read DVs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dvs \n",
    "DVs = pd.read_csv('./Input/DVs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DVs.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read IVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_IVs_plus_demo = pd.read_csv('./Input/All_IVs_plus_demo.csv')\n",
    "len(All_IVs_plus_demo.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read fb_Content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_content = pd.read_csv('./Input/fb_content.csv')\n",
    "len(fb_content.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DNN Model with a sub model \n",
    "def build_and_compile_dnn_model(input_shape):\n",
    "    # other_variables_num = len(All_IVs_without_reasons_to_use_FB.columns) # assume the number of variables is 67 here. In the real program, the number of input variables will be calcuated automatically. \n",
    "    # sub model \n",
    "    fb_content_input = keras.Input(shape=(21,), name='fb_content')\n",
    "    fb_content_hidden_layer = keras.layers.Dense(10, activation='relu')(fb_content_input)\n",
    "    fb_content_output = keras.layers.Dense(5, name='sub_output_layer', activation='softmax')(fb_content_hidden_layer)\n",
    "    # other part of model \n",
    "    fb_others_input = keras.Input(shape=(input_shape,))\n",
    "    fb_concatted_input = tf.keras.layers.Concatenate()([fb_content_output, fb_others_input]) # concat two types of input together \n",
    "    fb_concatted_hidden_layer1 = keras.layers.Dense(50, input_dim=2, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), bias_regularizer=regularizers.l2(1e-4), activation=tf.nn.relu)(fb_concatted_input)\n",
    "    fb_concatted_hidden_1_dropout = keras.layers.Dropout(.2, name='hidden1_Dropout')(fb_concatted_hidden_layer1)\n",
    "    fb_concatted_hidden_layer2 = keras.layers.Dense(50, input_dim=2, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), bias_regularizer=regularizers.l2(1e-4), activation=tf.nn.relu)(fb_concatted_hidden_1_dropout)\n",
    "    fb_concatted_hidden_2_dropout = keras.layers.Dropout(.2, name='hidden2_Dropout')(fb_concatted_hidden_layer2)\n",
    "    fb_concatted_output = keras.layers.Dense(15, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(fb_concatted_hidden_2_dropout)\n",
    "    model = tf.keras.Model(inputs=[fb_content_input, fb_others_input], outputs=fb_concatted_output)\n",
    "    learn_rate = 0.001\n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dvs \n",
    "DVs = pd.read_csv('./Input/DVs.csv')\n",
    "\n",
    "# BIG 5\n",
    "extraversion = DVs['extraversion']\n",
    "agreeableness = DVs['agreeableness']\n",
    "conscientiousness = DVs['conscientiousness']\n",
    "neuroticism = DVs['neuroticism']\n",
    "openness = DVs['openness']\n",
    "\n",
    "# Other Dvs \n",
    "implusiveness = DVs['implusiveness']\n",
    "rational = DVs['rational']\n",
    "experiential = DVs['experiential']\n",
    "normative_influence = DVs['normative.influence']\n",
    "informational_influence = DVs['informational.influence']\n",
    "\n",
    "# Potential DVs\n",
    "need_for_closure = DVs['need_for_closure']\n",
    "utilitarian = DVs['utilitarian']\n",
    "hedonic = DVs['hedonic']\n",
    "individual = DVs['individual']\n",
    "collective = DVs['collective']\n",
    "\n",
    "# create a list to store DVs\n",
    "DVs_list = [extraversion, agreeableness, conscientiousness, neuroticism, openness, implusiveness, rational, experiential,normative_influence, informational_influence, need_for_closure, utilitarian, hedonic, individual,collective ]\n",
    "DVs_list_name = [\"extraversion\", \"agreeableness\", \"conscientiousness\", \"neuroticism\", \"openness\", \"implusiveness\", \"rational\", \"experiential\",\"normative_influence\", \"informational_influence\", \"need_for_closure\", \"utilitarian\", \"hedonic\", \"individual\",\"collective\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average score from a list \n",
    "def average(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4918056745733551\n"
     ]
    }
   ],
   "source": [
    "input_val = [fb_content, All_IVs_plus_demo]\n",
    "for k in range(0, 1):\n",
    "    r2_list = []\n",
    "    dnn_model = build_and_compile_dnn_model(len(All_IVs_plus_demo.columns))\n",
    "    dnn_model.fit(input_val, DVs, validation_split=0.2, verbose=0, epochs=10000)\n",
    "    print(r2_score(DVs, dnn_model.predict(input_val)))\n",
    "    r2_ave_result = pd.DataFrame(columns = DVs_list_name)\n",
    "    r2_result = []\n",
    "    result = dnn_model.predict(input_val)\n",
    "    for k in range(0, 15):\n",
    "        dv_list = []\n",
    "        for i in range(0, 597):\n",
    "            dv_list.append(result[i][k])\n",
    "        r2_result.append(r2_score(DVs_list[k], np.array(dv_list)))\n",
    "all_r2_ave_list_series = pd.Series(r2_result, index = r2_ave_result.columns)\n",
    "r2_ave_result = r2_ave_result.append(all_r2_ave_list_series, ignore_index = True)\n",
    "today = time.strftime(\"%Y-%m-%d\")\n",
    "filename = 'r2_new'\n",
    "ave_file = today + filename + '.csv'\n",
    "r2_ave_result.to_csv(ave_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.121280269245354"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(DVs_list[0], np.array(dv_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(DVs, dnn_model.predict(input_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: dnn_model/assets\n"
     ]
    }
   ],
   "source": [
    "dnn_model.save(\"dnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36massets\u001b[m\u001b[m/         saved_model.pb  \u001b[1m\u001b[36mvariables\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls dnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = keras.models.load_model('dnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model.predict(input_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually input FB content data into the sub-model in the saved model, check the output layer of the sub-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_model = tf.keras.Model(load_model.get_layer(index = 0).output, load_model.get_layer(index = 2).output)\n",
    "inp = sub_model.predict(fb_content)\n",
    "sub_layer = tf.keras.layers.Softmax()\n",
    "sub_layer_result = pd.DataFrame(sub_layer(inp).numpy())\n",
    "today = time.strftime('%y-%m-%d-%H-%M-%S')\n",
    "sub_layer_file_name = today + '_sub_model_ouput.csv'\n",
    "sub_layer_result.to_csv(sub_layer_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
